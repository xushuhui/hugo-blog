
### 缓存模式 - 数据一致性
Storage 和 Cache 同步更新容易出现数据不一致。
模拟 MySQL Slave 做数据复制，再把消息投递到 Kafka，保证至少一次消费：
- 同步操作DB；
- 同步操作Cache；
- 利用Job消费消息，重新补偿一次缓存操作
保证时效性和一致性。
![image](https://tva3.sinaimg.cn/large/a616b9a4gy1gmrsl5mfirj20xx0towrc.jpg)

Cache Aside 模型中，读缓存 Miss 的回填操作，和修改数据同步更新缓存，包括消息队列的异步补偿缓存，都无法满足 “Happens Before”，会存在相互覆盖的情况。

![image](https://tva1.sinaimg.cn/large/a616b9a4gy1gmrsmxdfczj21q40j2tce.jpg)

读/写同时操作：
- 读操作，读缓存，缓存 MISS
- 读操作，读 DB，读取到数据
- 写操作，更新 DB 数据
- 写操作 SET/DELETE Cache（可 Job 异步操作）
- 读操作，SET操作数据回写缓存（可 Job 异步操作）
**这种交互下，由于4和5操作步骤都是设置缓存，导致写入的值互相覆盖；并且操作的顺序性不确定，从而导致 cache 存在脏缓存的情况。**
![image](https://tva2.sinaimg.cn/large/a616b9a4gy1gmsrl41kszj20ws0uhdwv.jpg)

读/写同时操作：
- 读操作，读缓存，缓存 MISS
- 读操作，读 DB，读取到数据
- 写操作，更新 DB 数据
- 写操作 SET Cache（可异步 job 操作，Redis 可以使用 SETEX 操作）
- 读操作，ADD 操作数据回写缓存（可 Job异步操作，Redis 可以使用 SETNX 操作）

**写操作使用 SET 操作命令，覆盖写缓存；读操作，使用 ADD 操作回写 MISS 数据，从而保证写操作的最新数据不会被读操作的回写数据覆盖。**

![image](https://tvax1.sinaimg.cn/large/a616b9a4gy1gmsrlf8ajcj20ws0uh17y.jpg)


### 缓存模式 - 多级缓存
微服务拆分细粒度原子业务下的整合服务（聚合服务），用于提供粗粒度的接口，以及二级缓存加速，减少扇出的 rpc 网络请求，减少延迟。
最重要是保证多级缓存的一致性：
- 清理的优先级是有要求的，先优先清理下游再上游；
- 下游的缓存expire要大于上游，里面穿透回源；

天下大势分久必合，适当的微服务合并也是不错的做法，再使用 DDD 思路以及我们介绍的目录结构组织方式，区分不同的 Usecase。
![image](https://tva4.sinaimg.cn/large/a616b9a4gy1gmsrmhpkifj20wj0fpq7l.jpg)

### 缓存模式 - 热点缓存
对于热点缓存 Key，按照如下思路解决：
- 小表广播，从 RemoteCache 提升为LocalCache，App 定时更新，甚至可以让运营平台支持广播刷新 LocalCache；
- 主动监控防御预热，比如直播房间页高在线情况下直接外挂服务主动防御；
- 基础库框架支持热点发现，自动短时的 short-live cache；
- 多 Cluster 支持；
    - 多 Key 设计: 使用多副本，减小节点热点的问题
使用多副本 ms_1,ms_2,ms_3 每个节点保存一份数据，使得请求分散到多个节点，避免单点热点问题。

![image](https://tvax2.sinaimg.cn/large/a616b9a4gy1gmsrp8ksz5j20x20ndqak.jpg)

建立多个 Cluster ，和微服务、存储等一起组成一个 Region。
这样相当于是用空间换时间：
**同一个 key 在每一个 frontend cluster 都可能有一个 copy，这样会带来 consistency 的问题，但是这样能够降低 latency 和提高 availability。利用 MySQL Binlog 消息 anycast 到不同集群的某个节点清理或者更新缓存；**
当业务频繁更新时候，cache频繁过期，会导致命中率低: stale sets
**如果应用程序层可以忍受稍微过期一点的数据，针对这点可以进一步降低系统负载。当一个key 被删除的时候（delete 请求或者 cache 爆棚清空间了），它被放倒一个临时的数据结构里，会再续上比较短的一段时间。当有请求进来的时候会返回这个数据并标记为“Stale”。对于大部分应用场景而言，Stale Value 是可以忍受的。(需要改 memcache、redis 源码，或者基础库支持）；**
![image](https://tvax3.sinaimg.cn/large/a616b9a4gy1gmsrqawix8j20xl0lvzsd.jpg)

### 缓存模式 - 穿透缓存

#### singlefly
对关键字进行一致性 hash，使其某一个维度的 key 一定命中某个节点，然后在节点内使用互斥锁，保证归并回源，但是对于批量查询无解；

#### 分布式锁
设置一个 lock key，有且只有一个人成功，并且返回，交由这个人来执行回源操作，其他候选者轮训 cache 这个 lock key，如果不存在去读数据缓存，hit 就返回，miss 继续抢锁；

#### 队列
如果 cache miss，交由队列聚合一个key，来 load 数据回写缓存，对于 miss 当前请求可以使用 singlefly 保证回源，如评论架构实现。适合回源加载数据重的任务，比如评论 miss 只返回第一页，但是需要构建完成评论数据索引。

#### lease
通过加入 lease 机制，可以很好避免这两个问题，lease 是 64-bit 的 token，与客户端请求的 key 绑定，对于过时设置，在写入时验证 lease，可以解决这个问题；对于 thundering herd，每个key 10s 分配一次，当 client 在没有获取到 lease 时，可以稍微等一下再访问 cache，这时往往cache 中已有数据。（基础库支持 & 修改 cache 源码）；


